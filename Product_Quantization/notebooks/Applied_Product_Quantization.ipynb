{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Product Quantization\n",
    "\n",
    "### Notebook written by Ryan Awad\n",
    "\n",
    "Is it feasible to use PQ in EigenDB and if so, how do we go about it?  \n",
    "\n",
    "Things to look into:\n",
    "- Training the quantizer with k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import ceil, log2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2(v: np.ndarray, u: np.ndarray) -> np.float32: # squared distance\n",
    "    return np.sum((v - u)**2)\n",
    "\n",
    "'''\n",
    "c_j is the SET of centroids for the specific sub-vector u_j\n",
    "\n",
    "this function finds the nearest centroid to a sub-vector and return's it's index (repoduction value)\n",
    "'''\n",
    "def quantizer(c_j: np.ndarray[np.ndarray], u_j: np.ndarray, k_: int) -> int:\n",
    "    distance = float('inf')\n",
    "    for i in range(k_):\n",
    "        new_dist = L2(c_j[i], u_j)\n",
    "        if new_dist < distance:\n",
    "            reprod_val = i\n",
    "            distance = new_dist\n",
    "    return reprod_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how each value in a vector is a float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = 12\n",
    "num_vectors = 100\n",
    "uncompressed_vectors = np.array([np.random.uniform(-100.0, 100.0, dim) for i in range(num_vectors)], dtype=np.float32)\n",
    "uncompressed_vectors[0][0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 4 # dimensions of a compressed vector\n",
    "\n",
    "assert dim % m == 0 # ensure dim is divisable by m\n",
    "\n",
    "D_ = int(dim / m) # length of each subvector will be dim / m (D* in notation)\n",
    "D_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 95.237755, -74.24087 ,  84.07467 ], dtype=float32),\n",
       " array([ 52.410015 , -56.440662 ,   7.3220177], dtype=float32),\n",
       " array([-27.519796, -64.44191 , -35.76187 ], dtype=float32),\n",
       " array([ -0.6291111,  96.73161  , -73.86947  ], dtype=float32)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now create the subvectors\n",
    "u_vectors = []\n",
    "for v in uncompressed_vectors:\n",
    "    u = [v[row:row+D_] for row in range(0, dim, D_)]\n",
    "    u_vectors.append(u)\n",
    "\n",
    "u_vectors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the codebook (clusters of centroids)\n",
    "\n",
    "IMPORTANT:\n",
    "- `k`: total number of centroids generated\n",
    "- `k_`: number of centroids to choose from per sub-vector\n",
    "\n",
    "Notice how when you increase `k`, `k_` will increase proportionally. And as `k_` increases, the compressed vector size also increases, WHILE the distances between the regenerated vectors and the actual vectors decrease. In addition, as `k_` increases, so does the time needed to generate the centroids, as well as compressing a vector.\n",
    "\n",
    "This is because as `k_` increases, each sub-vector gets to choose from a large amount of randomly generated centroids. Probablistically, a sub-vector will find a much better centroid than if `k_` was smaller which would give each sub-vector less options. This causes the average distance between regenerated vectors and actual vectors to decrease.\n",
    "\n",
    "In addition, as `k_` increases, each sub-vector will have a larger amount of centroids to choose from, making the compression algorithm take longer\n",
    "\n",
    "On the other hand, each sub-vector is converted into a centroid ID, as part of the compression algorithm. Since each sub-vector gets `k_` centroids to choose from, each ID will need to have allocated memory to store a value between 0 to `k_`-1. Therefore, as `k_` increases, the overall size of a compressed vector will increase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1024, k_=256\n"
     ]
    }
   ],
   "source": [
    "k = 2**10\n",
    "assert k % m == 0\n",
    "k_ = int(k/m)\n",
    "print(f\"{k=}, {k_=}\")\n",
    "#print(f\"Compressed vector size: {ceil(log2(k_)/8) * m} bytes\")\n",
    "#print(f\"Centroid map size: {ceil(k*D_*(32/8))} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = []  # codebook\n",
    "\n",
    "for j in range(m):\n",
    "    c_j = []\n",
    "    for i in range(k_):\n",
    "        c_ji = np.array(np.random.uniform(-100.0, 100.0, D_), dtype=np.float32)\n",
    "        c_j.append(c_ji)\n",
    "    c.append(c_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 95.237755  -74.24087    84.07467    52.410015  -56.440662    7.3220177\n",
      " -27.519796  -64.44191   -35.76187    -0.6291111  96.73161   -73.86947  ] -> [73, 162, 95, 236]\n"
     ]
    }
   ],
   "source": [
    "compressed_vectors = []\n",
    "for u in u_vectors:\n",
    "    curr_comp_vec = []\n",
    "    for j in range(m):\n",
    "        reprod_val = quantizer(c[j], u[j], k_)\n",
    "        curr_comp_vec.append(reprod_val)\n",
    "    compressed_vectors.append(curr_comp_vec)\n",
    "\n",
    "print(uncompressed_vectors[0], '->', compressed_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to create a distance table for a given uncompressed vector\n",
    "\n",
    "This gives us the ability to do distance comparisons with a uncompressed vector in the compressed space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24169.1484375 , 29064.4921875 ,  9789.89160156, 19856.9453125 ],\n",
       "       [15217.28515625, 23513.99414062, 32702.08203125, 25486.49804688],\n",
       "       [16749.4921875 , 27566.390625  , 17588.91601562, 39018.8046875 ],\n",
       "       ...,\n",
       "       [ 1924.79418945, 16783.17773438,  8501.57128906, 34256.4921875 ],\n",
       "       [16371.62109375, 20079.5390625 , 33898.39453125, 35699.234375  ],\n",
       "       [42122.5234375 , 17407.2421875 , 11267.71386719, 37905.22265625]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_distance_table(uncompressed_vector: np.ndarray) -> np.ndarray:\n",
    "    u = [uncompressed_vector[row:row+D_] for row in range(0, dim, D_)]\n",
    "    distance_table = np.zeros((k_, m))\n",
    "    for i in range(k_):\n",
    "        for j in range(m):\n",
    "            distance_table[i][j] = L2(u[j], c[j][i])\n",
    "    return distance_table\n",
    "\n",
    "random_query_vector = np.array(np.random.uniform(-100.0, 100.0, dim), dtype=np.float32)\n",
    "distance_table = create_distance_table(random_query_vector)\n",
    "distance_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining two naive $\\mathcal{O}(n \\log n)$ KNN algorithms. One using PQ compression and the other using uncompressed vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_pq(query_vector: np.ndarray, k: int) -> np.ndarray:\n",
    "    distance_table = create_distance_table(query_vector)\n",
    "    k_nearest = []\n",
    "    for v in compressed_vectors:\n",
    "        dist = 0\n",
    "        for i in range(len(v)):\n",
    "            dist += distance_table[v[i]][i]\n",
    "        k_nearest.append((dist, v))\n",
    "    k_nearest.sort(key=lambda x: x[0])\n",
    "    return k_nearest[:k]\n",
    "\n",
    "def knn(query_vector: np.ndarray, k: int) -> np.ndarray:\n",
    "    k_nearest = []\n",
    "    for v in uncompressed_vectors:\n",
    "        dist = L2(query_vector, v)\n",
    "        k_nearest.append((dist, v))\n",
    "    k_nearest.sort(key=lambda x: x[0])\n",
    "    return k_nearest[:k]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(np.float64(17564.37664794922), [238, 133, 100, 41]),\n",
       " (np.float64(19173.06591796875), [89, 190, 94, 91]),\n",
       " (np.float64(32791.091369628906), [19, 199, 33, 153]),\n",
       " (np.float64(34994.06628417969), [239, 249, 218, 193]),\n",
       " (np.float64(35544.838134765625), [92, 5, 79, 57])]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pq(random_query_vector, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(np.float32(15623.364),\n",
       "  array([-66.87325  , -60.600025 ,   1.1786443,  37.653828 ,  34.695995 ,\n",
       "          39.55513  ,  27.45343  , -26.210546 , -14.572233 , -21.175188 ,\n",
       "         -38.014748 ,  78.05014  ], dtype=float32)),\n",
       " (np.float32(16095.917),\n",
       "  array([-97.652664, -94.322845, -25.518024,  74.597916,  62.827755,\n",
       "          58.08905 ,  14.131105, -33.43935 , -72.77122 , -84.388336,\n",
       "          57.238464,  30.765211], dtype=float32)),\n",
       " (np.float32(28077.338),\n",
       "  array([-91.153046 ,   5.4039855, -66.23831  ,  44.655132 ,  86.018684 ,\n",
       "          39.98331  , -91.51644  , -93.11759  , -72.24697  , -31.703691 ,\n",
       "         -43.683704 , -35.177517 ], dtype=float32)),\n",
       " (np.float32(29262.8),\n",
       "  array([-75.76523 , -31.703144, -34.691883,  40.595818,  33.898514,\n",
       "         -82.49346 , -55.423103, -42.09285 , -49.451145, -47.776924,\n",
       "         -21.468914,   6.153912], dtype=float32)),\n",
       " (np.float32(29480.121),\n",
       "  array([-78.11101  ,  80.12574  , -30.671104 ,  63.099766 ,  59.020782 ,\n",
       "           1.6821917,  14.6666975,  35.94509  , -83.61682  ,   5.652181 ,\n",
       "         -26.719501 ,  15.807674 ], dtype=float32))]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn(random_query_vector, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
